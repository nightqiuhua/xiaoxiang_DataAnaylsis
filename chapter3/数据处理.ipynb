{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗与整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据介绍\n",
    "\n",
    "**station.csv** : 记录了美国旧金山海湾地区共享自行车站的信息，包含以下变量：\n",
    "- **id** :  车站编号\n",
    "- **name** :  车站名称\n",
    "- **lat** :  车站的纬度\n",
    "- **long** :  车站的经度\n",
    "- **docks** :  车站的码头数\n",
    "- **city** :  车站所在位置\n",
    "\n",
    "** trips1.csv、trips2.csv、trips3.csv** : 2013年8月底的所有trips, 包含以下变量：\n",
    "- **start_id** : trip的起始点\n",
    "- **end_id** : trip的终止点\n",
    "- **start_date** : trip的起始时间\n",
    "- **end_date** : trip的终止时间\n",
    "- **subscription_type** : 使用者类型（ 用户“Subscriber” 或者客户“Customer” ）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理过程将会完成以下各项：\n",
    "1. 导入 'station.csv' 数据，并且命名为 stations<br>\n",
    "   导入 'trips1.csv'、'trips2.csv'、'trips3.csv' 数据，并且分别命名为 trips1、trips2、trips3\n",
    "2. 将 trips1、trips2、trips3 合并为一个Dataframe, 命名为 trips\n",
    "3. 将 staions 中所有列名称前添加字段'start_'，并且将 start_id 设置为列索引\n",
    "4. 将 trips 和 stations 按照起始车站id进行字段匹配并合并，保留所有匹配成功的信息\n",
    "5. 将trips_stations 导出为' trips_stations.csv'文件\n",
    "6. 查看 trips_stations 中是否包含有重复值，并且将重复值删除\n",
    "7. 查看 trips_stations 中是否包含有缺失值，并且处理缺失值\n",
    "8. 去除 trips_stations 中 ‘start_name’ 列中每个字符串左右两边的空格和’#‘\n",
    "9. 将 'start_date' 和 'end_date' 中日期和时间进行拆分, 并分别记录在 'start_date'、'start_time'、'end_date'、'end_time'列\n",
    "10. 将每个终点车站数进行分组，分为<br>\n",
    "    '13以下', '13到15', '15到17', '17到19','19到21','21到23','23到25','25以上' 几类，<br>\n",
    "   并且在'start_docks'列右侧增加一列'start_docks_classification'记录每个车站数所属的分类 \n",
    "11. 将'subscription_type'转化为虚拟变量，添加在dateframe的最后一列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 导入 'station.csv' 数据，并且命名为 stations <br> <br>导入 'trips1.csv'、'trips2.csv'、'trips3.csv' 数据，并且分别命名为 trips1、trips2、trips3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 pandas 和 numpy 函数库\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入csv文件\n",
    "stations = pd.read_csv('./data/stations.csv', encoding= 'utf-8' )\n",
    "trips1 = pd.read_csv('./data/trips1.csv', encoding = 'utf-8')\n",
    "trips2 = pd.read_csv('./data/trips2.csv', encoding = 'utf-8')\n",
    "trips3 = pd.read_csv('./data/trips3.csv', encoding = 'utf-8')\n",
    "type(trips1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_csv()参数列表：<br>\n",
    "sep 指定分隔符 默认为','<br>\n",
    "names 指定列名列表,相当于给没有列标题的csv添加列索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 将 trips1、trips2、trips3 合并为一个Dataframe, 命名为 trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.concat([trips1,trips2,trips3])\n",
    "trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行之间的连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join = 'inner' 取两表的交集<br>\n",
    "join = 'outer 取两表的并集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat()的轴参数：<br>\n",
    "    axis = 0 列对齐，两表上下合并，每一列是增长了<br>\n",
    "    axis = 1 行对齐，两表左右合并，每一行是增长了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 将 staions 中所有列名称前添加字段'start_'，并且将 start_id 设置为列索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改列名称\n",
    "stations.columns #pandas index数组，表示列索引的集合\n",
    "stations.columns = stations.columns.map(lambda x: 'start_' + x) #注意要把map之后的赋值过去\n",
    "print(stations.columns)\n",
    "print(trips.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map() 会根据提供的函数对指定序列做映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 start_id 设置为列索引\n",
    "stations.set_index(['start_id'], inplace = True) #这里set_index也没有原地修改，不过inplace可以指定它原地修改\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 将 trips 和 stations 按照起始车站id进行字段匹配并合并，保留所有匹配成功的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 trips 和 stations 按照起始车站id进行匹配\n",
    "#别忘了merge就是增加新列\n",
    "trips_stations = pd.merge(trips, stations, left_on = 'start_id',right_on = 'start_id',\n",
    "                          how = 'left',right_index=True) #因为右边数据集使用的是index进行匹配，所以要加一个right_index参数\n",
    "#也要新加一个变量记录活动\n",
    "trips_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how = 'inner'(默认）未完全匹配的时候，保留已匹配的部分<br>\n",
    "how = 'left' 未完全匹配的时候，保留左边未匹配的部分<br>\n",
    "how = 'right'未完全匹配的时候，保留右边未匹配的部分<br>\n",
    "how = 'outer'未完全匹配的时候，保留两边所有未匹配的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trips.join(stations,how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 将trips_stations 导出为' trips_stations.csv'文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出csv文件\n",
    "trips_stations.to_csv('trips_stations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去除重复值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 查看 trips_stations 中是否包含有重复值，并且将重复值删除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只有某一行的所有元素与之前的某行完全相同时，才判断为相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看'stations'中是否存在重复值\n",
    "trips_stations_dup = trips_stations.duplicated() #返回一个series，索引是原来的行索引，值是True/False\n",
    "trips_stations[trips_stations_dup] #条件检索\n",
    "trips_stations_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除重复值\n",
    "trips_stations = trips_stations.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 检查重复值是否已被删除\n",
    "trips_stations_dup = trips_stations.duplicated()\n",
    "trips_stations_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 查看 trips_stations 中是否包含有缺失值，并且处理缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时将缺失值得样本剔除，有时填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看’trips'文件中是否含有缺失值\n",
    "isNA_trips_stations = trips_stations.isnull() #返回dataframe，每个元素都是True/False\n",
    "cond_na_row = isNA_trips_stations.any(axis=1)   #.any(axis=)方法，沿轴做或运算，只要该轴有一个True/Nonzero/...值就把这行判定为True,返回boolean series\n",
    "trips_stations[cond_na_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向上填充缺失值,用它同列上面的元素进行填充。非原地操作。返回series数组标识该列的值，再赋予该列。\n",
    "trips_stations['start_docks'] = trips_stations['start_docks'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向下填充缺失值。非原地操作。记得把填充后的列series赋给原列。\n",
    "trips_stations['start_docks'] = trips_stations['start_docks'].bfill()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中位数填充缺失值\n",
    "docks_median = trips_stations['start_docks'].median()\n",
    "trips_stations['start_docks'].fillna(docks_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改原数据\n",
    "docks_median = trips_stations['start_docks'].median\n",
    "trips_stations['start_docks'] = trips_stations['start_docks'].fillna(docks_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 lat、long 中的缺失值设置为‘未知’\n",
    "trips_stations['start_lat'] = trips_stations['start_lat'].fillna('未知')\n",
    "trips_stations['start_long'] = trips_stations['start_long'].fillna('未知')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除缺失值的样本\n",
    "trips_stations = trips_stations.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查’trips'中的缺失值是否已被删除\n",
    "isNA_trips_stations = trips_stations.isnull()\n",
    "trips_stations[isNA_trips_stations.any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理空格值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. 去除 trips_stations 中 ‘start_name’ 列中每个字符串左右两边的空格和’#‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对series数组使用.str()方法，可以把每个元素转换成字符串，然后用.strip()/.lstrip()/.rstrip()对每一个元素删除特定值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除'name'列中每个字符串左边的空格(开头空格）\n",
    "trips_stations['start_name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除'name'列中每个字符串右边的空格(尾部空格)\n",
    "trips_stations['start_name'].str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除'name'列中每个字符串左右两边的空格(头尾空格)，并且修改原数据\n",
    "trips_stations['start_name'] = trips_stations['start_name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除字符串左边的‘#’\n",
    "trips_stations['start_name'].str.lstrip('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 删除字符串左边的'#'\n",
    "trips_stations['start_name'].str.rstrip('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除字符串两边的'#',并且修改原数据\n",
    "trips_stations['start_name'] = trips_stations['start_name'].str.strip('#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字段拆分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是把一个字段（一列）按照某种规则竖着劈成两个或多个部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. 将 'start_date' 和 'end_date' 中日期和时间进行拆分, 并分别记录在 'start_date'、'start_time'、'end_date'、'end_time'列中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将'start_date'按照空格拆分成两列\n",
    "new_col_start = trips_stations['start_date'].str.split(' ', 1, True) #True表示返回dataframe, False表示返回series\n",
    "# 设置列名\n",
    "new_col_start.columns = ['start_date','start_time']\n",
    "# 将'trips_station'中'start_date'更改为new_col_start中的第一列\n",
    "trips_stations['start_date'] = new_col_start['start_date']\n",
    "# 在'start_date'右侧新增一列，记录'start_time'\n",
    "trips_stations.insert(loc = 3, column = 'start_time', value = new_col_start['start_time'])\n",
    "\n",
    "trips_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将'end_date'按照空格拆分成两列\n",
    "new_col_end = trips_stations['end_date'].str.split(' ', 1, True)\n",
    "print(new_col_end)\n",
    "# 设置列名\n",
    "new_col_end.columns = ['end_date','end_time']\n",
    "# 将'trips_station'中'end_date'更改为new_col_end中的第一列\n",
    "trips_stations['end_date'] = new_col_end['end_date']\n",
    "# 在'end_date'右侧添加一列，记录'end_time'\n",
    "trips_stations.insert(\n",
    "    loc = 5, column = 'end_time', \n",
    "    value = new_col_end['end_time'])\n",
    "\n",
    "trips_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.  将每个终点车站数进行分组，分为 <br>  \n",
    "####  '13以下', '13到15', '15到17', '17到19', '19到21', '21到23', '23到25', '25以上' 几类，<br>\n",
    "#### 并且在'start_docks'列右侧增加一列'start_docks_classification'记录每个车站数所属的分类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 输出'start_docks'的最小值和最大值\n",
    "print(min(trips_stations.start_docks), max(trips_stations.start_docks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置分组边界\n",
    "bins = [\n",
    "    min(trips_stations.start_docks)-1, 13, 15, 17, 19, 21, 23, 25,\n",
    "    max(trips_stations.start_docks)+1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照分组边界对'start_docks'进行分组\n",
    "cut = pd.cut(trips_stations.start_docks, bins, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置每个组的label\n",
    "labels = ['13以下', '13到15', '15到17', '17到19','19到21','21到23','23到25','25以上']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用'labels'代替数字\n",
    "cut = pd.cut(trips_stations.start_docks, bins, right=False, labels = labels) #right表示右边界是否包含,labels表示label\n",
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将列名转化为列名列表\n",
    "col_name = trips_stations.columns.tolist() #直接columns是Index数组类型\n",
    "# 在'start_docks'右侧添加一列，记录分组结果\n",
    "trips_stations.insert(\n",
    "    loc = col_name.index('start_docks')+1,  #如何很快得到想添加的列索引位置，省的一列列数过来。列表的index方法返回元素下标。\n",
    "    column = 'start_docks_classification',  #给插入列设置列索引\n",
    "    value = cut                             #列值\n",
    ")\n",
    "trips_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 添加虚拟变量（用编码代表非数值的值）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. 将'subscription_type'转化为虚拟变量，添加在dateframe的最后一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转化’subscription_type'为虚拟变量\n",
    "trips_stations_dummies = pd.get_dummies(\n",
    "    trips_stations,\n",
    "    columns = ['subscription_type'],\n",
    "    prefix=['subscription_type'],\n",
    "    prefix_sep=\"_\",  #sep后面是非数值的值，也就是重新定义列索引为：原列索引_值\n",
    "    dummy_na=False,\n",
    "    drop_first=False\n",
    ")\n",
    "\n",
    "trips_stations_dummies['subscription_type'] = trips_stations['subscription_type']\n",
    "# prefix 在没有列标题时，给列添加前缀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_stations_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
