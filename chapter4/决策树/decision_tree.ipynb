{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [决策树](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 加载相关模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 用于在jupyter中进行绘图\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  数据预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征名称： ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print('特征名称：', iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别： ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('类别：', iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取数据，将数据分为训练集和测试集，同时利用sklearn.preprocessing模块中的函数来对原始数据进行标准化，因为在一个范围内的数据会有效提高分类\n",
    "的准确性，一些基本的标准化数据的方法有：\n",
    "包括preprocessing.scale(X)<br>\n",
    "preprocessing.StandardScaler().fit(X)<br>\n",
    "preprocessing.MinMaxScaler().fit_transform(X_train)<br>\n",
    "preprocessing.MaxAbsScaler().fit_transform(X)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集样本数：150，训练集样本数：112，测试集样本数：38\n"
     ]
    }
   ],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/4, random_state=0)\n",
    "\n",
    "print('数据集样本数：{}，训练集样本数：{}，测试集样本数：{}'.format(len(X), len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('准确率：', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 查看超参数的影响\n",
    "决策树模型的参数：<br>\n",
    "max_depth_values:树的深度。其实不一定每个叶子节点都是只包含一类的节点，因为那会使模型变得复杂。所以可手动指定深度。<br>\n",
    "criterion：表示在基于特征划分数据集合时，选择特征的标准。默认是’gini‘，即'Gini impurity'(Gini不纯度)，还可以是criterion='entropy'<br>\n",
    "splitter：表示在构造树时，选择结点的原则，默认是splitter='best'，即选择最好的特征点分类，比如基于信息增益分类时，则选择信息增益最大的特征点，还可以是'random'<br>\n",
    "max_features->这个参数表示在划分数据集时考虑的最多的特征值数量，根据数据类型表示的意义也不同：int值->在每次split时，最大特征数；float->表示百分数<br>\n",
    "min_samples_split->int，float，optional(default=2)，表示在分解内部结点时最少的样本数<br>\n",
    "min_samples_leaf->int，float，optional(default=1)，表示每个叶结点最小的样本数目<br>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth= 2\n",
      "训练集上的准确率: 0.964\n",
      "测试集的准确率: 0.895\n",
      "\n",
      "max_depth= 3\n",
      "训练集上的准确率: 0.982\n",
      "测试集的准确率: 0.974\n",
      "\n",
      "max_depth= 4\n",
      "训练集上的准确率: 1.000\n",
      "测试集的准确率: 0.974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depth_values = [2, 3, 4]\n",
    "\n",
    "for max_depth_val in max_depth_values:\n",
    "    dt_model = DecisionTreeClassifier(max_depth=max_depth_val)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    print('max_depth=', max_depth_val)\n",
    "    print('训练集上的准确率: {:.3f}'.format(dt_model.score(X_train, y_train)))\n",
    "    print('测试集的准确率: {:.3f}'.format(dt_model.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 决策树可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要安装:\n",
    "* **graphviz程序**(已提供在代码目录下)，并将安装目录下的bin目录添加到环境变量中，**重启jupyter或系统生效**。如：C:\\Program Files (x86)\\Graphviz2.38\\bin 添加到系统PATH环境变量中。\n",
    "  \n",
    "* **graphviz模块**, pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \"\"\"\n\u001b[1;32m    205\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x1a0bea75c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml_visualization import plot_decision_tree\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=4)\n",
    "dt_model.fit(X_train, y_train)\n",
    "plot_decision_tree(dt_model, iris.feature_names, iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[0.02014872 0.02014872 0.40530263 0.55439994]\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)\n",
    "print(dt_model.feature_importances_) #衡量特征重要性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当特征非常多时，如何选取？通过特征重要性进行选取，进行降维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ml_visualization import plot_feature_importances\n",
    "plot_feature_importances(dt_model, iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益 Gain(D,A) = H(D)-H(D|A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
