{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小象学院实践课\n",
    "## 机器学习\n",
    "## IBM员工流失预测\n",
    "\n",
    "保持员工满意的问题是一个长期存在且历史悠久的挑战。如果您投入了大量时间和金钱的员工离开，那么这意味着您将不得不花费更多的时间和金钱来雇佣其他人。这个项目使用了IBM的员工流失数据作为处理目标，看看我们是否可以构建一些模型，来对员工的流失进行预测。\n",
    "\n",
    "> **提示**：这样的文字将会指导你如何使用 jupyter Notebook 来完成项目。你可以通过单击代码区域，然后使用键盘快捷键 Shift+Enter 或 Shift+Return 来运行代码。或者在选择代码后使用执行（run cell）按钮执行代码。Markdown的文字区域也同样可以如此操作。\n",
    "\n",
    "> 在如下有**# TODO** 提示的地方，将代码补全，实现注释中所要求的功能。\n",
    "\n",
    "> 在有\"** 回答：**\" 提示的地方，回答其上所提出的问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这个工程的结构如下：\n",
    "- 探索性数据分析：在本节中，我们通过查看特征分布，一个特征与另一个特征的相关性以及创建一些可视化图表来探索数据集。\n",
    "- 特征工程：执行一些简单的特征处理工作。\n",
    "- 实现机器学习模型：尝试多种机器学习模型，从这些模型中查看参数对结果的影响。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 探索数据\n",
    "运行下面的代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler ,LabelEncoder \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#文件读取\n",
    "attrition = pd.read_csv('./data/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "attrition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 观察\n",
    "从员工流失数据样本中，我们可以看到数据的一些特征：\n",
    "    * Age：员工年龄\n",
    "    * Attrition：员工是否已经离职，1表示已经离职，2表示未离职，这是目标预测值；\n",
    "    * BusinessTravel：商务差旅频率，Non-Travel表示不出差，Travel_Rarely表示不经常出差，Travel_Frequently表示经常出差；\n",
    "    * Department：员工所在部门，Sales表示销售部，Research & Development表示研发部，Human Resources表示人力资源部；\n",
    "    * DistanceFromHome：公司跟家庭住址的距离，从1到29，1表示最近，29表示最远；\n",
    "    * Education：员工的教育程度，从1到5，5表示教育程度最高；\n",
    "    * EducationField：员工所学习的专业领域，Life Sciences表示生命科学，Medical表示医疗，Marketing表示市场营销，Technical Degree表示技术学位，Human Resources表示人力资源，Other表示其他；\n",
    "    * EmployeeNumber：员工号码；\n",
    "    * EnvironmentSatisfaction：员工对于工作环境的满意程度，从1到4，1的满意程度最低，4的满意程度最高；\n",
    "    * Gender：员工性别，Male表示男性，Female表示女性；\n",
    "    * JobInvolvement：员工工作投入度，从1到4，1为投入度最低，4为投入度最高；\n",
    "    * JobLevel：职业级别，从1到5，1为最低级别，5为最高级别；\n",
    "    * JobRole：工作角色：Sales Executive是销售主管，Research Scientist是科学研究员，Laboratory Technician实验室技术员，Manufacturing Director是制造总监，Healthcare Representative是医疗代表，Manager是经理，Sales Representative是销售代表，Research Director是研究总监，Human Resources是人力资源；\n",
    "    * JobSatisfaction：工作满意度，从1到4，1代表满意程度最低，4代表满意程度最高；\n",
    "    * MaritalStatus：员工婚姻状况，Single代表单身，Married代表已婚，Divorced代表离婚；\n",
    "    * MonthlyIncome：员工月收入，范围在1009到19999之间；\n",
    "    * NumCompaniesWorked：员工曾经工作过的公司数；\n",
    "    * Over18：年龄是否超过18岁；\n",
    "    * OverTime：是否加班，Yes表示加班，No表示不加班；\n",
    "    * PercentSalaryHike：工资提高的百分比；\n",
    "    * PerformanceRating：绩效评估；\n",
    "    * RelationshipSatisfaction：关系满意度，从1到4，1表示满意度最低，4表示满意度最高；\n",
    "    * StandardHours：标准工时；\n",
    "    * StockOptionLevel：股票期权水平；\n",
    "    * TotalWorkingYears：总工龄；\n",
    "    * TrainingTimesLastYear：上一年的培训时长，从0到6，0表示没有培训，6表示培训时间最长；\n",
    "    * WorkLifeBalance：工作与生活平衡程度，从1到4，1表示平衡程度最低，4表示平衡程度最高；\n",
    "    * YearsAtCompany：在目前公司工作年数；\n",
    "    * YearsInCurrentRole：在目前工作职责的工作年数\n",
    "    * YearsSinceLastPromotion：距离上次升职时长\n",
    "    * YearsWithCurrManager：跟目前的管理者共事年数；\n",
    "\n",
    "在我们即将构建的机器学习模型当中，'Attrition'将是模型训练的目标列。\n",
    "\n",
    "此外，我们看到我们混合了数字和分类数据类型。 对于分类数据类型（非数字列），我们将在以后的练习中再尝试新的处理方法。 本节将专注于数字类型的相关属性探索。\n",
    "\n",
    "作为第一步，让我们快速进行一些简单的数据完整性检查，以查看数据中是否存在空值或无效值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 查看表中是否有空值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n",
    "数据集中有空值嘛？如果有，应该如何处理呢？\n",
    "\n",
    "** 回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的分布\n",
    "\n",
    "通常，探索数据的前几个步骤之一就是大致了解这些特征如何分布。\n",
    "\n",
    "直觉的判断，年龄(Age)、日工作效率（DailyRate）、员工满意度（JobSatisfaction）、月收入（MonthlyIncome）、工作表现（PerformanceRating）、工作生活平衡性（WorkLifeBalance）、进入公司年限（YearsAtCompany）这些属性与我们所关注的员工是否离职应有莫大的关系。\n",
    "\n",
    "为此，我将从Seaborn绘图库调用** pairplot **函数，将这些属性之间的关系用可视化的方式表示出来：（如果您没有安装seaborn，可以调用conda install seaborn进行安装）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 挑战小提示\n",
    "以下**TODO** 所需补充的代码逻辑，使用lambda和apply函数来完成可以让代码更为简洁和高效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# TODO\n",
    "# 将dataframe类型变量attrition中的Attrition列转化为Int类型，并放入一个新建的属性Attrition_numerical中。\n",
    "# Attrition列中的元素与Attrition_numerical元素的值对应关系是：'Yes'=>1，'No'=>0\n",
    "\n",
    "\n",
    "# 定义要绘制两两关系的属性列\n",
    "numerical = [u'Age', u'DailyRate',  u'JobSatisfaction',\n",
    "       u'MonthlyIncome', u'PerformanceRating',\n",
    "        u'WorkLifeBalance', u'YearsAtCompany', u'Attrition_numerical']\n",
    "\n",
    "# 绘制关系图\n",
    "g = sns.pairplot(attrition[numerical], hue='Attrition_numerical', palette='seismic', diag_kind = 'kde',diag_kws=dict(shade=True))\n",
    "g.set(xticklabels=[])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 观察\n",
    "在上图中，红色的点代表离职，蓝色代表未离职。\n",
    "\n",
    "我们可以看到一些有意思的结果，比如在MonthlyIncome与YearsAtCompany交汇的这张图中，红色点更趋向集中于左下角，这很明显地说明了MonthlyIncome与YearsAtCompany都相对较低时，员工容易出现离职的情况。\n",
    "\n",
    "再比如在YearsAtCompany这行对应的DailyRate这张图中，DailyRate的变化似乎对员工是否离职没有太多的影响。红色点集中于图像下部，YearsAtCompany小的员工相对更容易出现离职情况而与DailyRate没什么关系。\n",
    "\n",
    "### 探索\n",
    "这些关系具体如何更好的量化呢？让我们一起来探索一下吧！\n",
    "- 首先我们要将员工的流失情况记录下来，并将其从原表中删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 使用变量y记录attrition中'Attrition_numerical'这一列的值\n",
    "y = None\n",
    "\n",
    "# TODO\n",
    "# 将attrition中的'Attrition'以及'Attrition_numerical'列删除\n",
    "\n",
    "\n",
    "attrition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 属性类型判别\n",
    "在数据当中有很多列的都是由字符串组成的，在对数据集进行了简要的探索之后，现在让我们继续进行特征工程的任务，并对我们的数据集中的某些非数值属性进行数字编码。  \n",
    "\n",
    "首先，我们将通过使用dtype方法将数值列与非数值列分开，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categoricals列表将用于记录所有的非数值属性名\n",
    "categoricals = []\n",
    "\n",
    "# TODO\n",
    "# 将非数值列的列名添加到列表categoricals中，并且将这些非数值列的列名都打印出来   \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n",
    "为什么要将非数值属性进行数字编码？\n",
    "\n",
    "** 回答： **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征处理\n",
    "之后，我们对非数值属性进行处理，将他们转化为数值的形式。这里我们采用get_dummies方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pandas中的get_dummies方法将非数值列转为数字，并用转化好的列替换掉原本的列\n",
    "\n",
    "# 提取非数值类型\n",
    "# TODO\n",
    "# 将attrition中名字为categoricals中所记录的那些列数据提取出来，放到DataFrame类型的变量attrition_cat中\n",
    "attrition_cat = None\n",
    "\n",
    "# TODO\n",
    "# 使用pd.get_dummies将attrition_cat转换成数值形式并将结果覆盖赋值到原有变量attrition_cat之上\n",
    "attrition_cat = None\n",
    "\n",
    "# 提取数值类型\n",
    "# TODO\n",
    "# 获取attrition的数值类型属性列的所有数据，赋值到DataFrame类型的变量attrition_num上\n",
    "\n",
    "attrition_num = None\n",
    "\n",
    "# TODO\n",
    "# 将attrition_num与attrition_cat进行拼接，生成新的DataFrame并赋值到变量attrition_final上\n",
    "# attrition_final中的列由attrition_num与attrition_cat的列组成\n",
    "attrition_final = None\n",
    "\n",
    "attrition_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思考题\n",
    "- 我们可以看到，表格中数值分布较为分散，范围不一，比如DailyRate的值范围是一千多或者几百，HourlyRate的值大都为几时。这会对结果照成什么样的影响？如果我们将所有的数值全部限定在0-1范围内，会对结果又什么样的影响？\n",
    "\n",
    "**提示：** 参考归一化内容。\n",
    "\n",
    "** 回答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  模型应用\n",
    "\n",
    "我们将在 [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) 中选择以下监督学习模型对数据进行训练：\n",
    "- 高斯朴素贝叶斯 (GaussianNB)\n",
    "- 决策树 (DecisionTree)\n",
    "- K近邻 (K Nearest Neighbors)\n",
    "- 支持向量机 (SVM)\n",
    "- Logistic回归（LogisticRegression）\n",
    "---\n",
    "首先我们需要划分数据集为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# TODO\n",
    "# 使用train_test_split方法，划分训练集和测试集，指定80%数据为训练集，20%为测试集\n",
    "X_train, X_test, y_train, y_test = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n",
    "为什么需要将数据集划分为训练集和测试集?\n",
    "\n",
    "** 回答： **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "请建立SVM模型并计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# 准确率\n",
    "svm_acc=[]\n",
    "# TODO\n",
    "# 构建SVM模型（默认参数即可），并调用fit进行模型拟合\n",
    "\n",
    "\n",
    "\n",
    "# TODO\n",
    "# 计算svm在测试集上的准确率并将准确率结果添加到svm_acc中\n",
    "\n",
    "\n",
    "# 打印准确率\n",
    "print('准确率：', svm_acc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树\n",
    "请根据不同树深度建立决策树模型并计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 树深度\n",
    "depths=[1,3,5,7,9]\n",
    "# 准确率\n",
    "dt_acc=[]\n",
    "# TODO\n",
    "# 尝试depths中所列举的所有树深度情况，使用决策树模型做多次训练。\n",
    "# 针对每种树深情况计算一次在测试集上的准确率，打印每次训练所获得的准确率，并将每次准确率结果添入列表dt_acc中。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n",
    "- 从结果看，树的深度是越大，在测试集上的准确率越高么？随着深度增加模型在测试集上的准确率是否出现下降的情况？这一现象说明了什么？\n",
    "\n",
    "** 回答： **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯\n",
    "请建立朴素贝叶斯模型并计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 准确率\n",
    "gnb_acc=[]\n",
    "\n",
    "# TODO\n",
    "# 构建GaussianNB模型（默认参数即可），并调用fit进行模型拟合\n",
    "\n",
    "\n",
    "# TODO\n",
    "# 计算GaussianNB在测试集上的准确率并将准确率结果添加到gnb_acc中\n",
    "\n",
    "\n",
    "# 打印准确率\n",
    "print('准确率：', gnb_acc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "请建立KNN模型并计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# K参数选项\n",
    "neighbors = [1,3,5,7,9]\n",
    "# 准确率\n",
    "knn_acc=[]\n",
    "# TODO\n",
    "# 尝试neighbors中所列举的所有K选项，使用KNeighborsClassifier模型做多次训练。\n",
    "# 针对每种K值情况计算一次在测试集上的准确率，打印每次训练所获得的准确率，并将每次准确率结果添入列表knn_acc中。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归\n",
    "请建立逻辑回归模型并计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 准确率\n",
    "lr_acc=[]\n",
    "# TODO\n",
    "# 构建LogisticRegression模型（默认参数即可），并调用fit进行模型拟合\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO\n",
    "# 计算LogisticRegression在测试集上的准确率并将准确率结果添加到lr_acc中\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 打印准确率\n",
    "print('准确率：', lr_acc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n",
    "为什么我们可以使用逻辑回归模型进行分类呢？\n",
    "\n",
    "** 回答： **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果以图像展示出来\n",
    "results_df = pd.DataFrame(columns=['Accuracy (%)'],index=['svm','dt','gnb','knn','lr'])\n",
    "results_df.index.name = 'Model'\n",
    "results_df.loc['svm', 'Accuracy (%)'] = max(svm_acc) * 100\n",
    "results_df.loc['dt', 'Accuracy (%)'] = max(dt_acc) * 100\n",
    "results_df.loc['gnb', 'Accuracy (%)'] = max(gnb_acc) * 100\n",
    "results_df.loc['knn', 'Accuracy (%)'] = max(knn_acc) * 100\n",
    "results_df.loc['lr', 'Accuracy (%)'] = max(lr_acc) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "results_df.plot(y=['Accuracy (%)'], kind='bar', ylim=[70, 100], ax=ax1, title='Accuracy(%)', legend=False)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改进\n",
    "相对于准确率，F1值对模型的评价更为准确，下面就请你们算出以上五个模型的F1值,并通过柱形图展示出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 计算以上五个模型的F1值，保存在dataframe类型的变量results_df中并绘制成柱形图\n",
    "results_df = pd.DataFrame(columns=['f1'],index=['svm','dt','gnb','knn','lr'])\n",
    "results_df.index.name = 'Model'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题\n",
    "\n",
    "在这些模型中，你看到的SVM的F1值是多少？ 从F1值的角度评判该模型，所得到的好坏结论与从准确率角度评判所得结论是否相同？\n",
    "\n",
    "您认为在这里例子中，使用F1值与准确率进行模型评判，哪个指标更为合理？为什么？\n",
    "\n",
    "** 回答： **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
